\documentclass[12pt]{article}
\textwidth=7.0in \oddsidemargin=-0.5in \evensidemargin=-0.5in
\topmargin= -0.5in
\textheight=8.5in

\usepackage{amsmath, amsthm, amssymb, graphicx, epsfig}
\usepackage{algorithmic,algorithm}


%Equation commands

\newcommand{\ul}{\underline}
\newcommand{\bdm}{\begin{displaymath}}
\newcommand{\edm}{\end{displaymath}}
\newcommand{\beqas}{\begin{eqnarray*}}
\newcommand{\eeqas}{\end{eqnarray*}}
\newcommand{\bds}{\begin{description}}
\newcommand{\eds}{\end{description}}

%Symbols

\newcommand{\CA}{{\cal A}}
\newcommand{\CN}{{\cal N}}
\newcommand{\CQ}{{\cal Q}}
\newcommand{\CX}{{\cal X}}
\newcommand{\CY}{{\cal Y}}

\begin{document}
\thispagestyle{empty}



\begin{center}
{\Large\bf Math 226   \hfill NUMERICAL ANALYSIS}\\[8mm]
{\Large\bf  Midterm}\\[8mm]
October 23, 2015 \hfill Due October 30, 2015\\[5mm]
\end{center}

\vspace{20mm}

%\begin{center}
{\large \bf Show all of your work!!! For problems that include programming, please include the code and all outputted figures and tables.  Please label these clearly and refer to them appropriately in your answers to the questions.
}
%\end{center}

\vspace{20mm}

\noindent{\bf NAME: Sheng Xu }

\vspace{16mm}

\begin{center}
\hspace{1in}
\begin{tabular}{|c|c|@{\hspace{20mm}}r|}
\hline
\multicolumn{3}{|c|}{For Grading Only}\\
\hline\hline
\rule{0mm}{8mm}1& 20 & \\
\hline
\rule{0mm}{8mm}2& 15 &\\
\hline
\rule{0mm}{8mm}3& 20 &\\
\hline
\rule{0mm}{8mm}4& 15 &\\
\hline
\rule{0mm}{8mm}5& 30 &\\
\hline
\rule{0mm}{8mm}{\small $\sum$}&100 &\\
\hline
\end{tabular}
\end{center}

\vspace{20mm}

\newpage
\noindent
\author[{Sheng Xu}
\begin{enumerate}
\item Let $f(x) = e^x$, $x \in [0,1]$, find the best $L^{\infty}$ approximations to $f$ in $\mathcal{P}_0([0,1])$ and $\mathcal{P}_1([0,1])$, respectively. ($\mathcal{P}_k([0,1])$ is the space of polynomials whose degree is at most $k$)\\
Sol: For n=0, denote $E(x)=f(x) - b = e^x-b$, $x \in [0,1]$. Since we need (n+2) points in extreme set with alternative sign, we have two points with alternative sign. Since $E' (x) = e^x$ always bigger than 0 on $x \in [0,1]$, there would not be any extreme points except end points. Therefore:
\begin{align*}
E(0)=-E(1)\\
P_0=b=\frac {1+e}{2}
\end{align*}
For n=1, denote $E(x)=f(x) - ax - b = e^x-ax-b$, $x \in [0,1]$. Since we need (n+2) points in extreme set with alternative sign, we have three points with alternative sign. Since $E' (x) = e^x-a$ have at most one solution on $x \in [0,1]$, there would be one extreme points denote as $\xi$ except end points. So the line should be paralleled to the line crossing the end points $(0,1)$ and $(1,e)$, which is $y=(e-1)x+1$. \\
Now we try to find the extreme point beside end points. We know $a=e-1\approx 1.71828$. Therefore, $\xi=ln(e-1)$ which means the line is $y=(e-1)[x-ln(e-1)]+(e-1)$. Lastly we use $E(0)=-E(\xi)$ to get $b=\frac {1}{2}(1+e-1-(e-1)ln(e-1))\approx 0.89407$.
To sum up, $y=(e-1)x+\frac {1}{2}(1+e-1-(e-1)ln(e-1))\approx 1.71828x+0.89407$
\\

\item Let $f \in C^1([a,b])$, prove that the clamped cubic spline interpolation minimizes the quantity $\| g'' \|_{L^2([a,b])}$ among all functions $g \in C^2([a,b])$ which interpolate $f(x)$ at the $x_i$ and $f'(x)$ at $a$ and $b$.  (This implies that in a certain sense the cubic spline interpolant is the straightest, or smoothest, function satisfying the interpolations conditions).\\
Pf: define the Clamped Cubic Spline $C_s$, $\forall g \in C^2([a,b]$, define $K=C_s-g$. Therefore:
\begin{align*}
\| g'' \|&=\int_a^b \| g'' \|^2 \mathrm{d}x= \int_a^b \| C_s''- K''\|^2 \mathrm{d}x\\
& = \int_a^b \| C_s''\|^2 \mathrm{d}x + \int_a^b \|K''\|^2 \mathrm{d}x - 2 \int_a^b K''C_s'' \mathrm{d}x\\
\end{align*}
Obviously, $K''$ will reduce to $C^0([a,b])$, with the property of clamped cubic spline interpolation, if we integrate by part, we will get $\int_a^b K''C_s'' \mathrm{d}x=0$\\
Therefore:
\begin{align*}
\| g'' \| &= \int_a^b \| C_s''\|^2 \mathrm{d}x+ \int_a^b \|K''\|^2 \mathrm{d}x\\
& \geq \int_a^b \| C_s''\|^2 \mathrm{d}x &\mbox{since $\|K''\|^2$ is always bigger than 0}\\
\end{align*}
Hence, The clamped cubic spline interpolation minimizes the quantity $\| g'' \|_{L^2([a,b])}$ among all functions $g \in C^2([a,b])$ which interpolate $f(x)$ at the $x_i$ and $f'(x)$ at $a$ and $b$.
\
\item Derive a numerical integration rule of $\int_{a}^b f(x) \mathrm{d}x$ based on the Hermit interpolation of $f(x)$ using the two end points $a$ and $b$.  Then derive the Peano kernel for the obtained numerical integration and estimate the error.\\
Pf: As is defined by Lagrange Interpolation: $L(a)=\frac{x-b}{a-b}$; $L(b)=\frac{x-a}{b-a}$, Therefore:
\begin{align*}
& H(a)=L^{2}(a)[1-2L'(a)(x-a)]=(1-2\frac{x-a}{a-b})(\frac{x-b}{a-b})^{2}\\
& K(a)=L^{2}(a)(x-a)=(x-a)(\frac{x-b}{a-b})^{2}\\
& H(b)=L^{2}(b)[1-2L'(b)(x-b)]=(1-2\frac{x-b}{b-a})(\frac{x-a}{b-a})^{2}\\
& K(b)=L^{2}(b)(x-b)=(x-b)(\frac{x-a}{b-a})^{2}\\
\end{align*}
Now we calculate the weight according to $H(a)$ $K(a)$ $h(b)$ $K(b)$, where $H(a)$ $K(a)$ $h(b)$ $K(b)$ are all function of x:
\begin{align*}
W_{0,1}&=\int_a^b H(a)\mathrm{d}x=\int_a^b (\frac{x-b}{a-b})^{2}\mathrm{d}x-2\int_a^b \frac{x-a}{a-b}(\frac{x-b}{a-b})^{2}\\
&=\frac{1}{3}(b-a)+\frac{1}{6}(b-a)=\frac{1}{2}(b-a)\\
W_{0,2}&=\int_a^b H(b)\mathrm{d}x=\int_a^b (\frac{x-a}{b-a})^{2}\mathrm{d}x-2\int_a^b \frac{x-b}{b-a}(\frac{x-a}{b-a})^{2}\\
&=\frac{1}{3}(b-a)+\frac{1}{6}(b-a)=\frac{1}{2}(b-a)\\
W_{1,1}&=\int_a^b K(a)\mathrm{d}x=\int_a^b (x-a)(\frac{x-b}{a-b})^{2}\mathrm{d}x\\
&=\frac{1}{12}(b-a)^{2}\\
W_{1,2}&=\int_a^b K(b)\mathrm{d}x=\int_a^b (x-b)(\frac{x-a}{b-a})^{2}\mathrm{d}x\\
&=-\frac{1}{12}(b-a)^{2}\\
\end{align*}
Therefore, with $H(a)$ $K(a)$ $h(b)$ $K(b)$ are all function of x:
\begin{align*}
\int_a^b f(x)\mathrm{d}x&=\int_a^b f(a)H(a)+f(b)h(b)+f'(a)K(a)+f'(b)K(b)\mathrm{d}x\\
&=f(a)W_{0,1}+f(b)W_{0,2}+f'(a)W_{1,1}+f'(b)W_{1,2}\\
&=\frac{1}{2}(f(a)+f(b))(b-a)+\frac{1}{12}(f'(a)-f'(b))(b-a)^2\\
\end{align*}
Now we try to derive the Peano-Kernel. To do this we need to rewrite the equation:
\begin{align*}
K(t)=\frac{1}{(2n+1)!}\int_a^b (x-t)_{+}^{2n+1}\mathrm{d}x-\sum_{i=0}^{n} W_{0,i}(x_i-t)_{+}^{2n+1}+ W_{1,i} [\frac{\mathrm{d}}{\mathrm{d}x}(x_i-t)_{+}^{2n+1}]
\end{align*}
Since n=1. we have:
\begin{align*}
K(t) &=\frac{1}{3!}\int_a^b (x-t)_{+}^{3}\mathrm{d}x-\sum_{i=0}^{1} W_{0,i}(x_i-t)_{+}^{3}+  W_{1,i}[\frac{\mathrm{d}}{\mathrm{d}x}(x_i-t)_{+}^{3}]\\
&= \frac{1}{4!}(b-t)^{4}-\frac{1}{3!}[\frac{b-a}{2}(b-t)^3-\frac{(b-a)^2}{4}(b-t)^2]\\
\end{align*}
Now we can derive the error now: For some $\xi$ in $(a,b)$
\begin{align*}
E&=\int_a^b f^{(4)}(t)K(t)\mathrm{d}t\\
&=f^{(4)}(\xi) \int_a^b K(t)\mathrm{d}t\\
&=f^{(4)}(\xi) [\frac{1}{4!\cdot5}(b-t)^{5}-\frac{1}{4!\cdot2}(b-a)^5+\frac{1}{3!\cdot12}(b-a)^5]\\
&=f^{(4)}(\xi)[\frac{1}{4!*30}(b-t)^{5}]\\
&=\frac{1}{6!}f^{(4)}(\xi)(b-t)^{5}\\
\end{align*}
\
\item Consider a perturbed linear system $(A+\delta A)(x+\delta x) = b + \delta b$.  If $\| \delta A \| \| A^{-1} \| < 1$, show that
$$
\frac{\| \delta x \|}{\|x \|} \leq \frac{\kappa(A)}{1-\kappa(A) \frac{ \| \delta A\|}{\| A \|}} \left(  \frac{\| \delta A \|}{\| A \|} + \frac{\| \delta b \|}{\| b \|} \right)
$$
Pf: $(A+\delta A)(x+\delta x) = b + \delta b$\\
\begin{align*}
& Ax+\delta A\cdot x+A \delta x+\delta x \delta A = b + \delta b\\
& x\delta A+A \delta x+\delta x \delta A = \delta b\\
& \delta x = A^{-1}[\delta b-x\delta A-\delta x \delta A]\\
& \|\delta x \|\leq \| A^{-1}\|[\|\delta b\|+\|x\|\|\delta A\|+\|\delta x\| \|\delta A\|]\\
\end{align*}
Since $Ax=b$, so $\|b\|\leq \|A\|\|x\|$ \\
\begin{align*}
& \frac {\|\delta x \|-\| A^{-1}\|\|\delta A\|\|x\|-A^{-1}\|\|\delta x\| \|\delta A\|}{\|A\|\|x\|}\leq \frac {\| A^{-1}\|\|\delta b\|}{\|b\|}\\
& \frac {\|\delta x \|-\| A^{-1}\|\|\delta A\|\|x\|-A^{-1}\|\|\delta x\| \|\delta A\|}{\|x\|}\leq \frac {\|A\|\| A^{-1}\|\|\delta b\|}{\|b\|}=\frac {\kappa \|\delta b\|}{\|b\|}\\
& \frac {\|\delta x \|-\|A^{-1}\|\|\delta x\| \|\delta A\|}{\|x\|}\leq \frac {\kappa(A) \|\delta b\|}{\|b\|}+\| A^{-1}\|\|\delta A\|=\kappa(A) (\frac{\|\delta b\|}{\|b\|}+\frac{\|\delta A\|}{\|A\|})\\
& \frac {\|\delta x \|}{\|x\|}(1-\kappa(A) \frac {\|\delta A \|}{\|A\|}) \leq \kappa(A)(\frac{\|\delta b\|}{\|b\|}+\frac{\|\delta A\|}{\|A\|})
\end{align*}
Therefore, with $\| \delta A \| \| A^{-1} \| < 1$, i.e $\kappa(A) \frac {\|\delta A \|}{\|A\|}<1$:\\
$$
\frac{\| \delta x \|}{\|x \|} \leq \frac{\kappa(A)}{1-\kappa(A) \frac{ \| \delta A\|}{\| A \|}} \left(  \frac{\| \delta A \|}{\| A \|} + \frac{\| \delta b \|}{\| b \|} \right)
$$
\
\item
\begin{enumerate}
\item  Implement the LU factorization with partial pivoting ($PA = LU$).  The program should be a function that takes $A$ as the input and outputs $P$, $L$, $U$.  Test it with the following matrices
\begin{equation*} \label{eqn:1}
A =
\begin{pmatrix}
2 & 1 & 2 \\
1 & 2 & 3 \\
4 & 1 & 2
\end{pmatrix},
\
A =
\begin{pmatrix}
10 & 1 & 1 \\
1 & 10 & 1 \\
1 & 1 & 20
\end{pmatrix},
\
A = \texttt{hilb(5)},
\
A = \texttt{hilb(10)},
\
A = \texttt{hilb(20)}.
\end{equation*}
Report in each case $\frac{\| PA - LU \|_F}{\| L\|_F \| U \|_F}$ and $\frac{\| PA - LU \|_{F}}{\| A \|_F}$ and explain your results. (function \texttt{hilb(n)} in Matlab generates $n$-by-$n$ Hilbert matrix $A$ such that $a_{ij} = \frac{1}{i+j-1}$)
\

\item Implement the LU factorization with complete pivoting ($PAQ = LU$).  The program should be a function that takes $A$ as the input and outputs $P$, $Q$, $L$, $U$.  Test it with the above matrices, report $\frac{\| PAQ- LU \|_F}{\| L\|_F \| U \|_F}$ and $\frac{\| PAQ - LU \|_{F}}{\| A \|_F}$, and explain your results.\\
Ans: Let $e1=\frac{\| PA - LU \|_F}{\| L\|_F \| U \|_F}$, $e2=\frac{\| PA - LU \|_{F}}{\| A \|_F}$. Now we write down the error according to the matlab.\\
\begin{equation*} \label{eqn:1}
A_1 =
\begin{pmatrix}
2 & 1 & 2 \\
1 & 2 & 3 \\
4 & 1 & 2
\end{pmatrix},
\
A_2 =
\begin{pmatrix}
10 & 1 & 1 \\
1 & 10 & 1 \\
1 & 1 & 20
\end{pmatrix},
\
H_5 = \texttt{hilb(5)},
\
H_{10} = \texttt{hilb(10)},
\
H_{20} = \texttt{hilb(20)}.\\
\end{equation*}
\begin{center}
\bf{Table 5-1 Relationship between matrix and Error of calculation in Partial pivoting}
\end{center}
\tabcolsep0.2in
\begin{tabular}{|ccccccc|}
\hline
Matrix&$A_1$&$A_2$&$H_{5}$&$H_{10}$&$H_{20}$&\\
\hline
e1(*$10^{-16}$)&0.00000&0.00000&0.10506&0.07863&0.11342&\\
\hline
e2(*$10^{-16}$)&0.00000&0.00000&0.24829&0.28024&0.62891&\\
\hline
\end{tabular}
\
\begin{center}
\bf{Table 5-2 Relationship between matrix and Error of calculation in Complete pivoting}
\end{center}
\tabcolsep0.2in
\begin{tabular}{|ccccccc|}
\hline
Matrix&$A_1$&$A_2$&$H_{5}$&$H_{10}$&$H_{20}$&\\
\hline
e1(*$10^{-16}$)&0.10814&0.41884&0.13100&0.10198&0.13000&\\
\hline
e2(*$10^{-16}$)&0.16737&0.72300&0.30409&0.36456&0.72257&\\
\hline
\end{tabular}
\\
From the result, we can conclude that the partial Pivoting seems to have better accuracy than Complete Pivoting. \\
With Hilbert Matrix, we know when the size of matrix grows bigger, the error $e2$ will probably goes up, which is quite obvious in $e2=\frac{\| PA - LU \|_{F}}{\| A \|_F}$. But the growth is not so obvious in $e1=\frac{\| PA - LU \|_{F}}{\| L \|_F*\| U\|_F}$. In fact when we use \texttt{hilb(100)}, e1 seems to be relatively stable with value of $0.07571*10^{-16}$ for partial Pivoting, $0.21131*10^{-16}$ for complete Pivoting. while $e2$ grows to $10^{-15}$, ($0.12456*10^{-15}$ for the partial Pivoting and $0.33824*10^{-15}$ for the complete Pivoting).\\
Considering the difference of error for the first two matrix, it is easy to conclude that when we have some extreme value in matrix, we will get a bigger error. \\
However, no evidence is shown about the better stability of LU complete pivoting with the given matrix.\\
\\
A notification about discussion:\\
A discussion on the proof of the second Lemma about the Cubic Spline given in class which is related to Problem 2.\\
A discussion on the definition of Peano Kernel in Problem 3, mostly to confirm my thoughts.\\
Asking about the definition of $\|A\|_F$ of problem 5.\\
May have involved in other discussions, but mostly to offer help under limitation. So these did not affect the result of my answers.\\
\end{enumerate}

\end{enumerate}

\end{document}
